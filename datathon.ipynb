{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from pandas import DataFrame, Series\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import math as math\n",
    "import matplotlib.path as mplPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/EricYi/Desktop/Code/datathon_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def rand_samp_csv(filename, divisor=1000):\n",
    "    n = sum(1 for line in open(filename)) - 1 #number of records in file (excludes header)\n",
    "    s = int(n/divisor) #desired sample size\n",
    "    skip = sorted(random.sample(xrange(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
    "    df = pd.read_csv(filename, skiprows=skip)\n",
    "    print \"done\"\n",
    "    return df\n",
    "\n",
    "# non-trip data\n",
    "geographic = pd.read_csv('geographic.csv')\n",
    "demographics = pd.read_csv(\"demographics.csv\")\n",
    "zones = pd.read_csv(\"zones.csv\")\n",
    "\n",
    "# uber trip data\n",
    "uber_2014 = rand_samp_csv(\"uber_trips_2014.csv\")\n",
    "uber_2015 = rand_samp_csv(\"uber_trips_2015.csv\")\n",
    "\n",
    "# green trip data\n",
    "green_trips = rand_samp_csv(\"green_trips.csv\")\n",
    "\n",
    "# yellow trip data\n",
    "yellow_trips_2014Q2 = rand_samp_csv(\"yellow_trips_2014Q2.csv\")\n",
    "yellow_trips_2014Q3 = rand_samp_csv(\"yellow_trips_2014Q3.csv\")\n",
    "yellow_trips_2015Q1 = rand_samp_csv(\"yellow_trips_2015Q1.csv\")\n",
    "yellow_trips_2015Q2 = rand_samp_csv(\"yellow_trips_2015Q2.csv\")\n",
    "\n",
    "# other data\n",
    "other_fhv_trips = rand_samp_csv(\"other_fhv_trips.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# merging trips with zones based on Taxi Zones to obtain NTA codes from zones\n",
    "uber_zones_2015 = uber_2015.merge(zones, left_on='pickup_location_id', right_on='location_id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merging trips and zones with demographics based on NTA codes to obtain demographics\n",
    "final_uber_2015 = uber_zones_2015.merge(demographics, left_on='nta_code', right_on='nta_code', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_Dates(sample):\n",
    "    # converts datetimes to dates\n",
    "    sample['pickup_date'] = pd.DatetimeIndex(\n",
    "        sample['pickup_datetime'].apply(pd.to_datetime)).date\n",
    "    print \"datetime conversion done\"\n",
    "    sample['count'] = 1\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute NTA Paths\n",
    "NTA_names = geographic.loc[[1]]\n",
    "NTA_paths = []\n",
    "for x in NTA_names:\n",
    "    geo_x_filtered = filter(lambda k: not math.isnan(k), geographic[x])\n",
    "    num_vertices = min(2000, len(geo_x_filtered))\n",
    "    polygon = map(lambda i: [geo_x_filtered[2*i], geo_x_filtered[2*i+1]], xrange(0, num_vertices/2))\n",
    "    NTA_paths.append((x, mplPath.Path(np.array(polygon))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_districts(sample, rows):\n",
    "    sLength = len(sample['pickup_datetime'])\n",
    "    sample['nta_code'] = Series(np.random.randn(sLength))\n",
    "\n",
    "    start_time = time.time()\n",
    "    districts = []\n",
    "    counter = 0\n",
    "    for index, row in sample[0:rows].iterrows():\n",
    "        counter += 1000\n",
    "        latitude = row['pickup_latitude']\n",
    "        longitude = row['pickup_longitude']\n",
    "\n",
    "        loc = \"None\"\n",
    "        if (len(districts) % 1000 == 0):\n",
    "            print \"i = \", counter\n",
    "        for (district, path) in NTA_paths:\n",
    "            if path.contains_point((longitude, latitude)):\n",
    "                loc = district\n",
    "                break\n",
    "        districts.append(loc)\n",
    "    time_taken = time.time() - start_time\n",
    "    print 'time taken: ', time_taken\n",
    "    return districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insertDistricts(sample, districts):\n",
    "    sample[\"nta_code\"] = districts\n",
    "    sample[\"count\"] = 1\n",
    "    print \"districts done\"\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def merge_withDemo(sample):\n",
    "    return sample.merge(demographics, left_on='nta_code', right_on='nta_code', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_stuff(sample, filenames):\n",
    "    use = sample.groupby(by=[\"nta_code\", \"pickup_date\"])\n",
    "    final = use.sum()\n",
    "    final.to_csv(filenames[0])\n",
    "    \n",
    "    #use2 = sample.groupby(by=[\"nta_code\"])\n",
    "    #final2 = use2.sum()\n",
    "    #final2.to_csv(filenames[1])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime conversion done\n",
      "i =  1000\n",
      "i =  1001000\n",
      "i =  2001000\n",
      "i =  3001000\n",
      "i =  4001000\n",
      "time taken:  6.67237377167\n",
      "districts done\n",
      "datetime conversion done\n",
      "i =  1000\n",
      "i =  1001000\n",
      "i =  2001000\n",
      "i =  3001000\n",
      "i =  4001000\n",
      "i =  5001000\n",
      "i =  6001000\n",
      "i =  7001000\n",
      "i =  8001000\n",
      "i =  9001000\n",
      "i =  10001000\n",
      "i =  11001000\n",
      "i =  12001000\n",
      "i =  13001000\n",
      "i =  14001000\n",
      "i =  15001000\n",
      "i =  16001000\n",
      "i =  17001000\n",
      "time taken:  21.8658368587\n",
      "districts done\n",
      "datetime conversion done\n",
      "i =  1000\n",
      "i =  1001000\n",
      "i =  2001000\n",
      "i =  3001000\n",
      "i =  4001000\n",
      "i =  5001000\n",
      "i =  6001000\n",
      "i =  7001000\n",
      "i =  8001000\n",
      "i =  9001000\n",
      "i =  10001000\n",
      "i =  11001000\n",
      "i =  12001000\n",
      "i =  13001000\n",
      "i =  14001000\n",
      "i =  15001000\n",
      "i =  16001000\n",
      "i =  17001000\n",
      "i =  18001000\n",
      "i =  19001000\n",
      "i =  20001000\n",
      "i =  21001000\n",
      "i =  22001000\n",
      "i =  23001000\n",
      "i =  24001000\n",
      "i =  25001000\n",
      "i =  26001000\n",
      "i =  27001000\n",
      "i =  28001000\n",
      "i =  29001000\n",
      "i =  30001000\n",
      "i =  31001000\n",
      "i =  32001000\n",
      "i =  33001000\n",
      "i =  34001000\n",
      "i =  35001000\n",
      "i =  36001000\n",
      "i =  37001000\n",
      "i =  38001000\n",
      "i =  39001000\n",
      "i =  40001000\n",
      "i =  41001000\n",
      "i =  42001000\n",
      "i =  43001000\n",
      "time taken:  55.2451560497\n",
      "districts done\n",
      "datetime conversion done\n",
      "i =  1000\n",
      "i =  1001000\n",
      "i =  2001000\n",
      "i =  3001000\n",
      "i =  4001000\n",
      "i =  5001000\n",
      "i =  6001000\n",
      "i =  7001000\n",
      "i =  8001000\n",
      "i =  9001000\n",
      "i =  10001000\n",
      "i =  11001000\n",
      "i =  12001000\n",
      "i =  13001000\n",
      "i =  14001000\n",
      "i =  15001000\n",
      "i =  16001000\n",
      "i =  17001000\n",
      "i =  18001000\n",
      "i =  19001000\n",
      "i =  20001000\n",
      "i =  21001000\n",
      "i =  22001000\n",
      "i =  23001000\n",
      "i =  24001000\n",
      "i =  25001000\n",
      "i =  26001000\n",
      "i =  27001000\n",
      "i =  28001000\n",
      "i =  29001000\n",
      "i =  30001000\n",
      "i =  31001000\n",
      "i =  32001000\n",
      "i =  33001000\n",
      "i =  34001000\n",
      "i =  35001000\n",
      "i =  36001000\n",
      "i =  37001000\n",
      "i =  38001000\n",
      "i =  39001000\n",
      "time taken:  52.2538158894\n",
      "districts done\n",
      "datetime conversion done\n",
      "i =  1000\n",
      "i =  1001000\n",
      "i =  2001000\n",
      "i =  3001000\n",
      "i =  4001000\n",
      "i =  5001000\n",
      "i =  6001000\n",
      "i =  7001000\n",
      "i =  8001000\n",
      "i =  9001000\n",
      "i =  10001000\n",
      "i =  11001000\n",
      "i =  12001000\n",
      "i =  13001000\n",
      "i =  14001000\n",
      "i =  15001000\n",
      "i =  16001000\n",
      "i =  17001000\n",
      "i =  18001000\n",
      "i =  19001000\n",
      "i =  20001000\n",
      "i =  21001000\n",
      "i =  22001000\n",
      "i =  23001000\n",
      "i =  24001000\n",
      "i =  25001000\n",
      "i =  26001000\n",
      "i =  27001000\n",
      "i =  28001000\n",
      "i =  29001000\n",
      "i =  30001000\n",
      "i =  31001000\n",
      "i =  32001000\n",
      "i =  33001000\n",
      "i =  34001000\n",
      "i =  35001000\n",
      "i =  36001000\n",
      "i =  37001000\n",
      "i =  38001000\n",
      "time taken:  52.3363001347\n",
      "districts done\n",
      "datetime conversion done\n",
      "i =  1000\n",
      "i =  1001000\n",
      "i =  2001000\n",
      "i =  3001000\n",
      "i =  4001000\n",
      "i =  5001000\n",
      "i =  6001000\n",
      "i =  7001000\n",
      "i =  8001000\n",
      "i =  9001000\n",
      "i =  10001000\n",
      "i =  11001000\n",
      "i =  12001000\n",
      "i =  13001000\n",
      "i =  14001000\n",
      "i =  15001000\n",
      "i =  16001000\n",
      "i =  17001000\n",
      "i =  18001000\n",
      "i =  19001000\n",
      "i =  20001000\n",
      "i =  21001000\n",
      "i =  22001000\n",
      "i =  23001000\n",
      "i =  24001000\n",
      "i =  25001000\n",
      "i =  26001000\n",
      "i =  27001000\n",
      "i =  28001000\n",
      "i =  29001000\n",
      "i =  30001000\n",
      "i =  31001000\n",
      "i =  32001000\n",
      "i =  33001000\n",
      "i =  34001000\n",
      "i =  35001000\n",
      "i =  36001000\n",
      "i =  37001000\n",
      "i =  38001000\n",
      "time taken:  51.7045359612\n",
      "districts done\n"
     ]
    }
   ],
   "source": [
    "# uber_2015,other_fhv_trips are the frames without coordinates\n",
    "df_loc_list = [uber_2014, green_trips, yellow_trips_2014Q2,\n",
    " yellow_trips_2014Q3, yellow_trips_2015Q1, yellow_trips_2015Q2]\n",
    "for i in xrange(len(df_loc_list)):\n",
    "    sample = df_loc_list[i]\n",
    "    df_loc_list[i] = merge_withDemo(insertDistricts(to_Dates(sample), find_districts(sample, len(sample))))\n",
    "\n",
    "#output_stuff(final_uber_2015, [\"IMBALANCED_uber_trips_2015_days.csv\", \"IMBALANCED_uber_trips_2015_year.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = df_loc_list[0]\n",
    "\n",
    "def merger(sample):\n",
    "    use = sample[[\"service\", \"nta_code\", \"pickup_date\", \"count\", \"population\", \"median_age\", \"households\",\n",
    "              \"median_income\", \"people_per_acre\"]].groupby(by=[\"service\", \"nta_code\", \"pickup_date\"])\n",
    "    final = use.agg({'count': 'sum', 'population': 'mean', 'median_age': 'median',\n",
    "                'households': 'mean', 'median_income': 'median', 'people_per_acre': 'mean'})\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime conversion done\n"
     ]
    }
   ],
   "source": [
    "# this is so ugly\n",
    "\n",
    "#df_loc_list = [uber_2014, green_trips, yellow_trips_2014Q2,\n",
    "# yellow_trips_2014Q3, yellow_trips_2015Q1, yellow_trips_2015Q2]\n",
    "#uber_zones_2015\n",
    "\n",
    "uber_2014['service'] = 'uber'\n",
    "uber_2014F = merger(merge_withDemo(uber_2014))\n",
    "uber_2014F.columns=[\"count\",\"avg_ppl_per_acre\", \"median_median_income\", \"median_median_age\", \"avg_households\",\n",
    "                  \"avg_population\"]\n",
    "\n",
    "uber_zones_2015s = uber_zones_2015\n",
    "uber_zones_2015s['service'] = \"uber\"\n",
    "uber_2015F = merger(merge_withDemo(to_Dates(uber_zones_2015)))\n",
    "uber_2015F.columns=[\"count\",\"avg_ppl_per_acre\", \"median_median_income\", \"median_median_age\", \"avg_households\",\n",
    "                  \"avg_population\"]\n",
    "\n",
    "green_trips[\"service\"] = \"green\"\n",
    "green_tripsF = merger(merge_withDemo(green_trips))\n",
    "green_tripsF.columns=[\"count\",\"avg_ppl_per_acre\", \"median_median_income\", \"median_median_age\", \"avg_households\",\n",
    "                  \"avg_population\"]\n",
    "\n",
    "yellow_trips_2014Q2[\"service\"] = \"yellow\"\n",
    "yellow_trips_2014Q2F = merger(merge_withDemo(yellow_trips_2014Q2))\n",
    "yellow_trips_2014Q2F.columns=[\"count\",\"avg_ppl_per_acre\", \"median_median_income\", \"median_median_age\", \"avg_households\",\n",
    "                  \"avg_population\"]\n",
    "\n",
    "yellow_trips_2014Q3[\"service\"] = \"yellow\"\n",
    "yellow_trips_2014Q3F = merger(merge_withDemo(yellow_trips_2014Q3))\n",
    "yellow_trips_2014Q3F.columns=[\"count\",\"avg_ppl_per_acre\", \"median_median_income\", \"median_median_age\", \"avg_households\",\n",
    "                  \"avg_population\"]\n",
    "\n",
    "yellow_trips_2015Q1[\"service\"] = \"yellow\"\n",
    "yellow_trips_2015Q1F = merger(merge_withDemo(yellow_trips_2015Q1))\n",
    "yellow_trips_2015Q1F.columns=[\"count\",\"avg_ppl_per_acre\", \"median_median_income\", \"median_median_age\", \"avg_households\",\n",
    "                  \"avg_population\"]\n",
    "\n",
    "yellow_trips_2015Q2[\"service\"] = \"yellow\"\n",
    "yellow_trips_2015Q2F = merger(merge_withDemo(yellow_trips_2015Q2))\n",
    "yellow_trips_2015Q2F.columns=[\"count\",\"avg_ppl_per_acre\", \"median_median_income\", \"median_median_age\", \"avg_households\",\n",
    "                  \"avg_population\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "big_Frame = pd.concat([uber_2014F, uber_2015F, green_tripsF, yellow_trips_2014Q2F,\n",
    "                       yellow_trips_2014Q3F, yellow_trips_2015Q1F, yellow_trips_2015Q2F])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "big_Frame.to_csv(\"big_frame_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "green_trips = rand_samp_csv(\"green_trips.csv\")\n",
    "green_trips_Af = merge_withDemo(insertDistricts(to_Dates(green_trips), find_districts(green_trips, len(green_trips))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "green_trips_Af['service'] = 'green'\n",
    "green_trips_f = merger(green_trips_Af)\n",
    "green_trips_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uber_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
